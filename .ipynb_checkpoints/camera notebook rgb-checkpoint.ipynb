{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from keras.models import load_model\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "#for voice support\n",
    "engine = pyttsx3.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def say_sth(msg):\n",
    "    engine.say(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "eye_cascade =cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model_rgb.h5')\n",
    "\n",
    "image_x, image_y = 100,100\n",
    "\n",
    "dict_labels = {\n",
    "              0:'zero',\n",
    "              1:'one',\n",
    "              2:'two',\n",
    "              3:'three',\n",
    "              4:'four',\n",
    "              5:'five',\n",
    "              6:'six',\n",
    "              7:'seven',\n",
    "              8:'eight',\n",
    "              9:'nine',\n",
    "             10:'ten'\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_process_image(img):\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (1, image_x, image_y, 3))\n",
    "    return img\n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    pred_probab = model.predict(processed)\n",
    "    #print(\"pred_probab:\",pred_probab,\"\\n\")\n",
    "    pred_class =np.argmax(pred_probab)\n",
    "    return np.max(pred_probab), pred_class\n",
    "\n",
    "def resize_save(image):\n",
    "    resize = cv2.resize(image, (100, 100)) \n",
    "    cv2.imwrite(\"resized.jpg\", resize)\n",
    "    print(\"images saved\")\n",
    "    \n",
    "def save_image(img,i):\n",
    "    cv2.imwrite('dataset/test/2/'+str(i)+'.jpg', img)\n",
    "    print(\"images saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_circle(img,center,radius,color):\n",
    "    cv.Circle(img, center, radius, color, thickness=1, lineType=8, shift=0) \n",
    "\n",
    "def put_splitted_text_in_blackboard(blackboard, splitted_text):\n",
    "    y = 200\n",
    "    for text in splitted_text:\n",
    "        cv2.putText(blackboard, text, (4, y), cv2.FONT_HERSHEY_TRIPLEX, 2, (255, 255, 255))\n",
    "        y += 50\n",
    "\n",
    "def show_txt():\n",
    "    blackboard = np.zeros((100, 400, 3), dtype=np.uint8)\n",
    "    splitted_text = split_sentence(\"hello world i am manish\", 1)\n",
    "    put_splitted_text_in_blackboard(blackboard, splitted_text)\n",
    "    cv2.imshow(\"Recognizing gesture\", blackboard)\n",
    "\n",
    "def split_sentence(text, num_of_words):\n",
    "    '''\n",
    "    Splits a text into group of num_of_words\n",
    "    '''\n",
    "    list_words = text.split(\" \")\n",
    "    length = len(list_words)\n",
    "    splitted_sentence = []\n",
    "    b_index = 0\n",
    "    e_index = num_of_words\n",
    "    while length > 0:\n",
    "        part = \"\"\n",
    "        for word in list_words[b_index:e_index]:\n",
    "            part = part + \" \" + word\n",
    "        splitted_sentence.append(part)\n",
    "        b_index += num_of_words\n",
    "        e_index += num_of_words\n",
    "        length -= num_of_words\n",
    "    return splitted_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-b71e99928bd6>:29: SyntaxWarning: name 'pred_class' is assigned to before global declaration\n",
      "  global pred_class\n",
      "<ipython-input-20-b71e99928bd6>:30: SyntaxWarning: name 'prob' is assigned to before global declaration\n",
      "  global prob\n"
     ]
    }
   ],
   "source": [
    "cap = None\n",
    "def recognize():\n",
    "    #defining size for rectangle\n",
    "    x,y = 200,200\n",
    "    w,h = 300,300\n",
    "    threshold = 15\n",
    "    \n",
    "    pred_class = 10 #firstly intialized to be null\n",
    "    prob =None  #variable declaration for probability\n",
    "    global cap\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    i = 0\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, gray = cap.read()\n",
    "        \n",
    "        cropped_img = gray[x+threshold:x+w-threshold,y+threshold:y+h-threshold]\n",
    "        # Our operations on the frame come here\n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        # Display the resulting frame\n",
    "        cv2.rectangle(gray,(x,y),(x+w,y+h),(0,0,0),2)\n",
    "        \n",
    "        blackboard = np.zeros(gray.shape, dtype=np.uint8)\n",
    "        \n",
    "            \n",
    "        if(i%10==0):\n",
    "            global pred_class\n",
    "            global prob\n",
    "            prob, pred_class =keras_predict(model,cropped_img)\n",
    "            say_sth(dict_labels[pred_class])\n",
    "        put_splitted_text_in_blackboard(blackboard,[str(dict_labels[pred_class]),'probability:',str(prob)])\n",
    "        \n",
    "        res = np.hstack((gray, blackboard))\n",
    "        cv2.imshow('frame',res)\n",
    "        \n",
    "        keypress = cv2.waitKey(1)\n",
    "        if keypress == ord('q'):\n",
    "            destroy_window()\n",
    "            break\n",
    "        elif keypress == ord('c'):\n",
    "            save_image(cropped_img,i) #if pressed c save the image \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def destroy_window():\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n",
      "images saved\n"
     ]
    }
   ],
   "source": [
    "recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#face detection code\n",
    "\n",
    "#  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(gray,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#         roi_gray = gray[y:y+h, x:x+w]\n",
    "#         roi_color = gray[y:y+h, x:x+w]\n",
    "#         print(\"====face detected========\")\n",
    "#         eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         for (ex,ey,ew,eh) in eyes:\n",
    "#             print(\"====eye detected========\")\n",
    "#             cv2.rectangle(roi_gray,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create a black image\n",
    "# img = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "# # Draw a diagonal blue line with thickness of 5 px\n",
    "# cv2.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "# cv2.imshow(\"drawing shapes\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
